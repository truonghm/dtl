{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.imdb.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(path_url):\n",
    "    try:\n",
    "        full_url = base_url + path_url\n",
    "        headers = {'User-Agent': 'Thunder Client (https://www.thunderclient.com)'}\n",
    "\n",
    "        time.sleep(1)\n",
    "        res = requests.get(full_url, headers)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        return soup\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def extract_runtime(text):\n",
    "    for time_format in ('%H hours %M minutes', '%H hour %M minutes', '%H hours %M minute', '%H hour %M minute'):\n",
    "        try:\n",
    "            timeobj = datetime.datetime.strptime(text, time_format).time()\n",
    "            delta = datetime.datetime.combine(datetime.date.min, timeobj) - datetime.datetime.min\n",
    "            return int(delta.total_seconds()/60)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "def extract_opening_date(text):\n",
    "    months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    patterns = \"(\" + \")|(\".join(months) + \")\"\n",
    "    full_patterns = f\"(.*)(?={patterns})\"\n",
    "    return datetime.datetime.strptime(re.sub(full_patterns, \"\", text), '%b %d, %Y')\n",
    "\n",
    "def extract_release_date(text):\n",
    "    text = re.sub(\" \\(.*?\\)\", \"\", text)\n",
    "    for time_format in ('%B %d, %Y', '%Y', '%b %d, %Y'):\n",
    "        try:\n",
    "            return datetime.datetime.strptime(text, time_format)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "def extract_revenue_usa_opening(text):\n",
    "    months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    patterns = \"(\" + \")|(\".join(months) + \")\"\n",
    "    full_patterns = f\"(.*)(?={patterns})\"\n",
    "    new_text = re.sub(\"[\\$,]\", \"\", re.sub(re.sub(full_patterns, \"\", text), \"\", text))\n",
    "    if new_text.isnumeric():\n",
    "        return int(new_text)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_rating_count(rating_url):\n",
    "    soup = get_soup(rating_url)\n",
    "    \n",
    "    text = soup.select_one(\"div.allText > div.allText\").text.split(\"\\n\")[1].strip()\n",
    "    text_num = \"\".join(re.findall(\"[0-9]+\", text))\n",
    "    return text_num\n",
    "    \n",
    "def get_review_count(user_review_url):\n",
    "    soup = get_soup(user_review_url)\n",
    "    \n",
    "    text = soup.select(\"div.header > div > span\")[0].text\n",
    "    text_num = \"\".join(re.findall(\"[0-9]+\", text))\n",
    "    return text_num.replace(\",\", \"\").strip()\n",
    "\n",
    "def mapping_key(label):\n",
    "    res = []\n",
    "\n",
    "    if label in (\"Director\", \"Directors\"):\n",
    "        res = [\"directors\"]\n",
    "    elif label in (\"Writer\", \"Writers\"):\n",
    "        res = [\"writers\"]\n",
    "    elif label in (\"Star\", \"Stars\"):\n",
    "        res = [\"stars\"]\n",
    "    elif label in (\"Genre\", \"Genres\"):\n",
    "        res = [\"genres\"]\n",
    "    elif label in (\"Country of origin\", \"Countries of origin\"):\n",
    "        res = [\"country\"]\n",
    "    elif label in (\"Language\", \"Languages\"):\n",
    "        res = [\"language\"]\n",
    "    elif label == \"Budget\":\n",
    "        res = [\"budget\"]\n",
    "    elif label == \"Gross US & Canada\":\n",
    "        res = [\"revenue_usa\"]\n",
    "    elif label == \"Opening weekend US & Canada\":\n",
    "            res = [\"revenue_usa_opening\", \"opening_date\"]\n",
    "    elif label == \"Gross worldwide\":\n",
    "        res = [\"revenue_world\"]\n",
    "    elif label == \"Runtime\":\n",
    "        res = [\"runtime\"]\n",
    "    elif label == \"Release date\":\n",
    "        res = [\"release_date\"]\n",
    "\n",
    "    return res\n",
    "\n",
    "def extract_list_item(label, content):\n",
    "\n",
    "    res = None, None\n",
    "\n",
    "    if label in (\"Director\", \"Directors\"):\n",
    "        res = \"directors\", re.sub(\"\\(.*?\\)\", \",\", content).strip(\",\").split(\",\")\n",
    "    elif label in (\"Writer\", \"Writers\"):\n",
    "        res = \"writers\", re.sub(\"\\(.*?\\)\", \",\", content).strip(\",\").split(\",\")\n",
    "    elif label in (\"Star\", \"Stars\"):\n",
    "        res = \"stars\", re.sub(\"\\(.*?\\)\", \",\", content).strip(\",\").split(\",\")\n",
    "    elif label in (\"Genre\", \"Genres\"):\n",
    "        res = \"genres\", content\n",
    "    elif label in (\"Country of origin\", \"Countries of origin\"):\n",
    "        res = \"country\", content  \n",
    "    elif label in (\"Language\", \"Languages\"):\n",
    "        res = \"language\", content    \n",
    "    elif label == \"Budget\":\n",
    "        text = re.sub(\"(\\(.*?\\))|(\\$)|(,)\", \"\", content).strip()\n",
    "        if text.isnumeric():\n",
    "            res = \"budget\", int(text)\n",
    "    elif label == \"Gross US & Canada\":\n",
    "        text = re.sub(\"(\\(.*?\\))|(\\$)|(,)\", \"\", content).strip()\n",
    "        if text.isnumeric():\n",
    "            res = \"revenue_usa\", int(text)\n",
    "    elif label == \"Opening weekend US & Canada\":\n",
    "        if \"$\" in content:\n",
    "            res = \"revenue_usa_opening\", extract_revenue_usa_opening(content)\n",
    "        else:\n",
    "            res = \"opening_date\", extract_opening_date(content)\n",
    "    elif label == \"Gross worldwide\":\n",
    "        text = re.sub(\"(\\(.*?\\))|(\\$)|(,)\", \"\", content).strip()\n",
    "        if text.isnumeric():\n",
    "            res = \"revenue_world\", int(text)\n",
    "    elif label == \"Runtime\":\n",
    "        res = \"runtime\", extract_runtime(content)\n",
    "    elif label == \"Release date\":\n",
    "        res = \"release_date\", extract_release_date(content)\n",
    "\n",
    "    return res\n",
    "\n",
    "def extract_list(label, inner_content):\n",
    "    \n",
    "    res = None, None\n",
    "\n",
    "    if len(inner_content) == 1:\n",
    "        res = extract_list_item(label, inner_content[0])\n",
    "    else:\n",
    "        label_key = None\n",
    "        content_list = []\n",
    "        for content in inner_content:\n",
    "            label_key, content_value = extract_list_item(label, content)\n",
    "            if type(content_value) != list:\n",
    "                content_list.append(content_value)\n",
    "            else:\n",
    "                content_list.extend(content_value)\n",
    "                \n",
    "        res = label_key, content_list\n",
    "\n",
    "    return res\n",
    "\n",
    "def extract_crew_url(label, url_http):\n",
    "    if url_http:\n",
    "        crew_urls = [k['href'] for k in url_http]\n",
    "\n",
    "        if label in (\"Director\", \"Directors\"):\n",
    "            res = \"directors_url\", crew_urls\n",
    "        elif label in (\"Writer\", \"Writers\"):\n",
    "            res = \"writers_url\", crew_urls\n",
    "        else:\n",
    "            res = None, []\n",
    "\n",
    "        return res\n",
    "    else:\n",
    "        return None, []\n",
    "\n",
    "class MovieCrawler():\n",
    "    \n",
    "    def __init__(self, path_url):\n",
    "\n",
    "        self.movie = dict(\n",
    "            name = None,\n",
    "            popularity = None,\n",
    "            rating = None,\n",
    "            rating_url = None,\n",
    "            rating_count = None,\n",
    "            user_review_count = None,\n",
    "            critic_review_count = None,\n",
    "            # metascore = None,\n",
    "            directors = [],\n",
    "            directors_url = [],\n",
    "            writers = [],\n",
    "            writers_url = [],\n",
    "            top_cast = [],\n",
    "            top_cast_url = [],\n",
    "            stars = [],\n",
    "            genres = [],\n",
    "            country = [],\n",
    "            language = [],\n",
    "            budget = None,\n",
    "            revenue_usa = None,\n",
    "            revenue_usa_opening = None,\n",
    "            revenue_world = None,\n",
    "            runtime = None,\n",
    "            opening_date = None,\n",
    "            release_date = None,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            self.soup = get_soup(path_url=path_url)\n",
    "        except Exception as e:\n",
    "            self.soup = None\n",
    "            print(repr(e))\n",
    "\n",
    "    def extract_info(self, c, label_http, url_http):\n",
    "        if label_http:\n",
    "            label = label_http[0].text\n",
    "            all_keys = mapping_key(label)\n",
    "\n",
    "            if len(all_keys) == 0:\n",
    "                return\n",
    "            elif len(all_keys) == 1:\n",
    "                if  not (self.movie[all_keys[0]] is None or len(self.movie[all_keys[0]]) == 0):\n",
    "                    return\n",
    "\n",
    "            else:\n",
    "                check = any([self.movie[ak] is None or len(self.movie[ak]) == 0 for ak in all_keys])\n",
    "                if not check:\n",
    "                    return\n",
    "            \n",
    "            if label in (\"Director\", \"Directors\", \"Writer\", \"Writers\"):\n",
    "                url_key, url_val = extract_crew_url(label, url_http)\n",
    "                # print(url_key, url_val)\n",
    "                if url_key in ('directors_url','writers_url'):\n",
    "                    if len(self.movie[url_key]) == 0:\n",
    "                        self.movie[url_key] = url_val\n",
    "\n",
    "            # content = c.text.replace(label, \"\")\n",
    "            http = c.select(\"a.ipc-metadata-list-item__list-content-item.ipc-metadata-list-item__list-content-item--link\")\n",
    "            inner_content = [s.text for s in http]\n",
    "            # print(label, inner_content)\n",
    "            key, value = extract_list(label, inner_content)\n",
    "            if key is not None:\n",
    "                if (self.movie[key] is None or len(self.movie[key]) == 0):\n",
    "                    self.movie[key] = value\n",
    "                    return\n",
    "            else:\n",
    "                http = c.select(\"span.ipc-metadata-list-item__list-content-item\")\n",
    "                if len(http) != 0:\n",
    "                    inner_content = [s.text for s in http]\n",
    "\n",
    "                    for content in inner_content:\n",
    "                        # print(content)\n",
    "                        key, value = extract_list_item(label, content)\n",
    "                        if key is not None and (self.movie[key] is None or len(self.movie[key]) == 0):\n",
    "                            self.movie[key] = value\n",
    "                else:\n",
    "                    http = c.select_one(\"div.ipc-metadata-list-item__content-container\")\n",
    "                    if http is not None:\n",
    "                        content = http.text\n",
    "                        # print(content)\n",
    "                        key, value = extract_list_item(label, content)\n",
    "                        if key is not None and (self.movie[key] is None or len(self.movie[key]) == 0):\n",
    "                            self.movie[key] = value\n",
    "\n",
    "    def get_movie_info(self):\n",
    "        if self.soup is None:\n",
    "            return self.movie\n",
    "            \n",
    "        try:\n",
    "            self.movie['name'] = self.soup.select_one(\"h1.sc-b73cd867-0.eKrKux\").text\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            self.movie['popularity'] = self.soup.select_one(\"div.sc-edc76a2-1.gopMqI\").text\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        self.movie['top_cast'] = [actor.text for actor in self.soup.select(\"a.sc-11eed019-1.jFeBIw\")]\n",
    "        self.movie['top_cast_url'] = [actor['href'] for actor in self.soup.select(\"a.sc-11eed019-1.jFeBIw\")]\n",
    "        rating_http = self.soup.select(\"a.ipc-button ipc-button--single-padding ipc-button--center-align-content ipc-button--default-height ipc-button--core-baseAlt ipc-button--theme-baseAlt ipc-button--on-textPrimary ipc-text-button sc-f6306ea-2 dfHGIi\".replace(\" \", \".\"))\n",
    "\n",
    "        rating = rating_http[0].select(\"span.sc-7ab21ed2-1.jGRxWM\")[0].text\n",
    "        try:\n",
    "            self.movie['rating'] = float(rating)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        self.movie['rating_url'] = rating_http[0]['href']\n",
    "\n",
    "        # rating_count = get_rating_count(rating_http[0]['href'])\n",
    "        # if rating_count.isnumeric():\n",
    "        #     self.movie['rating_count'] = int(rating_count)\n",
    "\n",
    "        user_review_url = self.soup.select(\"a.ipc-link ipc-link--baseAlt ipc-link--touch-target sc-124be030-2 eshTwQ isReview\".replace(\" \", \".\"))[0]['href']\n",
    "        user_review_count = get_review_count(user_review_url)\n",
    "        if user_review_count.isnumeric():\n",
    "            self.movie['user_review_count'] = int(user_review_count)\n",
    "\n",
    "        critic_review_count = self.soup.select(\"a.ipc-link ipc-link--baseAlt ipc-link--touch-target sc-124be030-2 eshTwQ isReview\".replace(\" \", \".\"))[1].text.replace(\",\",\"\").replace(\"Critic reviews\", \"\")\n",
    "        if critic_review_count.isnumeric():\n",
    "            self.movie['critic_review_count'] = int(critic_review_count)\n",
    "        \n",
    "        # metascore = self.soup.select(\"a.ipc-link ipc-link--baseAlt ipc-link--touch-target sc-124be030-2 eshTwQ isReview\".replace(\" \", \".\"))[2].text.replace(\",\",\"\").replace(\"Metascore\", \"\")\n",
    "        # if metascore.isnumeric():\n",
    "        #     self.movie['metascore'] = int(metascore)\n",
    "\n",
    "        http1 = self.soup.select(\"li.ipc-metadata-list__item\")\n",
    "        http2 = self.soup.select(\"li.ipc-metadata-list__item.ipc-metadata-list-item--link\")\n",
    "\n",
    "        for c in http1:\n",
    "            label_http = c.select(\"span.ipc-metadata-list-item__label\")\n",
    "            url_http = c.select(\"a.ipc-metadata-list-item__list-content-item.ipc-metadata-list-item__list-content-item--link\")\n",
    "            self.extract_info(c, label_http, url_http)\n",
    "\n",
    "        for c in http2:\n",
    "            label_http = c.select(\"a.ipc-metadata-list-item__label.ipc-metadata-list-item__label--link\")\n",
    "            url_http = c.select(\"a.ipc-metadata-list-item__list-content-item.ipc-metadata-list-item__list-content-item--link\")\n",
    "            self.extract_info(c, label_http, url_http)\n",
    "\n",
    "        return self.movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_path = \"/title/tt0118849/\"\n",
    "# movie_url = base_url + movie_path\n",
    "# headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "# res = requests.get(movie_url, headers)\n",
    "# soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# http2 = soup.select(\"li.ipc-metadata-list__item.ipc-metadata-list-item--link\")\n",
    "\n",
    "# for c in http2:\n",
    "#     label_http = c.select(\"a.ipc-metadata-list-item__label.ipc-metadata-list-item__label--link\")\n",
    "#     if label_http:\n",
    "#         label = label_http[0].text\n",
    "#         if label == \"Release date\":\n",
    "#             http = c.select(\"a.ipc-metadata-list-item__list-content-item.ipc-metadata-list-item__list-content-item--link\")\n",
    "#             inner_content = [s.text for s in http]\n",
    "#             print(inner_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawler = MovieCrawler(\"/title/tt0118849/\")\n",
    "# crawler.get_movie_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 57/250 [07:35<2:22:31, 44.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt1853728/reviews?ref_=tt_ov_rt&User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f017ab609d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 148/250 [18:15<1:13:47, 43.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt0057115/?User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f018040ee20>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 165/250 [22:00<1:02:40, 44.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt0347149/?User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f017b729550>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 197/250 [27:07<38:59, 44.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt2119532/reviews?ref_=tt_ov_rt&User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f017bb71160>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 210/250 [30:27<29:01, 43.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt0097165/?User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f01803c5ac0>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 243/250 [35:39<05:06, 43.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='www.imdb.com', port=443): Max retries exceeded with url: //title/tt0025316/?User-Agent=Thunder+Client+%28https%3A%2F%2Fwww.thunderclient.com%29 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f017b8746a0>: Failed to establish a new connection: [Errno 110] Connection timed out'))\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [36:18<00:00,  8.71s/it]\n"
     ]
    }
   ],
   "source": [
    "def crawl_movie_data(crawler, status, movie_name, movie_rating_count, movie_index, movie_url):\n",
    "    if status:\n",
    "        movie_dict = crawler.get_movie_info()\n",
    "    else:\n",
    "        movie_dict = crawler.movie\n",
    "\n",
    "    if movie_dict['name'] is None:\n",
    "        movie_dict['name'] = movie_name\n",
    "    if movie_dict['rating_count'] is None:\n",
    "        if movie_rating_count.isnumeric():\n",
    "            movie_dict['rating_count'] = movie_rating_count\n",
    "    movie_dict['id'] = movie_index\n",
    "    movie_dict['url'] = movie_url\n",
    "\n",
    "    return movie_dict\n",
    "\n",
    "top250_url = \"/chart/top\"\n",
    "top250_soup = get_soup(top250_url)\n",
    "urls = [element.attrs.get('href') for element in top250_soup.select('td.titleColumn a')]\n",
    "movie_names = top250_soup.select('td.titleColumn')\n",
    "movie_rating_counts = [element.attrs.get('data-value') for element in top250_soup.select('td.posterColumn span[name=nv]')]\n",
    "\n",
    "movie_list = []\n",
    "for index, url in tqdm(enumerate(urls), total = len(urls)):\n",
    "    crawler = MovieCrawler(url)\n",
    "    # time.sleep(1)\n",
    "    try:\n",
    "        movie_dict = crawl_movie_data(crawler, True, movie_names[index], movie_rating_counts[index], index, url)\n",
    "        movie_list.append(movie_dict)\n",
    "    except Exception as e:\n",
    "        movie_dict = crawl_movie_data(crawler, False, movie_names[index], movie_rating_counts[index], index, url)\n",
    "        movie_list.append(movie_dict)\n",
    "        print(repr(e))\n",
    "    # if index == 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './cache/raw_movie_data.json'\n",
    "with open(file_name, 'w+') as f:\n",
    "    f.write(json.dumps(movie_list, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_df = pd.DataFrame({\n",
    "    \"name\": [item for sublist in list(df['writers']) for item in sublist], \n",
    "    \"url\": [item for sublist in list(df['writers_url']) for item in sublist]\n",
    "})\n",
    "writers_df['url'] = writers_df['url'].str.replace(\"(?<=\\?)(.*)|(\\?)\", \"\", regex=True)\n",
    "writers_df.drop_duplicates(inplace=True)\n",
    "writers_df.set_index('url', inplace=True)\n",
    "\n",
    "directors_df = pd.DataFrame({\n",
    "    \"name\": [item for sublist in list(df['directors']) for item in sublist], \n",
    "    \"url\": [item for sublist in list(df['directors_url']) for item in sublist]\n",
    "})\n",
    "directors_df['url'] = directors_df['url'].str.replace(\"(?<=\\?)(.*)|(\\?)\", \"\", regex=True)\n",
    "directors_df.drop_duplicates(inplace=True)\n",
    "directors_df.set_index('url', inplace=True)\n",
    "\n",
    "actors_df = pd.DataFrame({\n",
    "    \"name\": [item for sublist in list(df['top_cast']) for item in sublist], \n",
    "    \"url\": [item for sublist in list(df['top_cast_url']) for item in sublist]\n",
    "})\n",
    "actors_df['url'] = actors_df['url'].str.replace(\"(?<=\\?)(.*)|(\\?)\", \"\", regex=True)\n",
    "actors_df.drop_duplicates(inplace=True)\n",
    "actors_df.set_index('url', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars_url(top_cast, top_cast_url, stars):\n",
    "    return [v for k,v in zip(top_cast, top_cast_url) if k in stars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars_url'] = df.apply(lambda x: get_stars_url(x.top_cast, x.top_cast_url, x.stars), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cast_df = df[['id', 'top_cast_url']].explode(['top_cast_url'])\n",
    "top_cast_df.columns = ['movie_id', 'actor_url']\n",
    "stars_df = df[['id', 'stars_url']].explode(['stars_url'])\n",
    "stars_df.columns = ['movie_id', 'actor_url']\n",
    "stars_df['is_star'] = True\n",
    "actor_movie_df = top_cast_df.merge(stars_df, how='left', on=['movie_id', 'actor_url'])\n",
    "actor_movie_df['is_star'] = actor_movie_df['is_star'].fillna(False)\n",
    "director_movie_df = df[['id', 'directors_url']].explode(['directors_url'])\n",
    "writers_movie_df = df[['id', 'writers_url']].explode(['writers_url'])\n",
    "genres_movie_df = df[['id', 'genres']].explode(['genres'])\n",
    "country_movie_df = df[['id', 'country']].explode(['country'])\n",
    "language_movie_df = df[['id', 'language']].explode(['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id','url','name','popularity','rating','rating_url','rating_count','user_review_count','critic_review_count','budget','revenue_usa','revenue_usa_opening','revenue_world','runtime','opening_date','release_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_url</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>critic_review_count</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue_usa</th>\n",
       "      <th>revenue_usa_opening</th>\n",
       "      <th>revenue_world</th>\n",
       "      <th>runtime</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>/title/tt1853728/</td>\n",
       "      <td>Hành Trình Django</td>\n",
       "      <td>178</td>\n",
       "      <td>8.4</td>\n",
       "      <td>/title/tt1853728/ratings/?ref_=tt_ov_rt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>/title/tt0057115/</td>\n",
       "      <td>[\\n      148.\\n      , [Cuộc Đào Thoát Vĩ Đại]...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>240548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>/title/tt0347149/</td>\n",
       "      <td>[\\n      165.\\n      , [Lâu Đài Di Động Của Ho...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>378601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>/title/tt2119532/</td>\n",
       "      <td>Người Hùng Không Súng</td>\n",
       "      <td>239</td>\n",
       "      <td>8.1</td>\n",
       "      <td>/title/tt2119532/ratings/?ref_=tt_ov_rt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>/title/tt0097165/</td>\n",
       "      <td>[\\n      210.\\n      , [Dead Poets Society], \\...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>471368.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>/title/tt0025316/</td>\n",
       "      <td>[\\n      243.\\n      , [Chuyện Xảy Ra Trong Đê...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>102143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                url  \\\n",
       "56    56  /title/tt1853728/   \n",
       "147  147  /title/tt0057115/   \n",
       "164  164  /title/tt0347149/   \n",
       "196  196  /title/tt2119532/   \n",
       "209  209  /title/tt0097165/   \n",
       "242  242  /title/tt0025316/   \n",
       "\n",
       "                                                  name popularity  rating  \\\n",
       "56                                   Hành Trình Django        178     8.4   \n",
       "147  [\\n      148.\\n      , [Cuộc Đào Thoát Vĩ Đại]...       None     NaN   \n",
       "164  [\\n      165.\\n      , [Lâu Đài Di Động Của Ho...       None     NaN   \n",
       "196                              Người Hùng Không Súng        239     8.1   \n",
       "209  [\\n      210.\\n      , [Dead Poets Society], \\...       None     NaN   \n",
       "242  [\\n      243.\\n      , [Chuyện Xảy Ra Trong Đê...       None     NaN   \n",
       "\n",
       "                                  rating_url  rating_count  user_review_count  \\\n",
       "56   /title/tt1853728/ratings/?ref_=tt_ov_rt           NaN                NaN   \n",
       "147                                     None      240548.0                NaN   \n",
       "164                                     None      378601.0                NaN   \n",
       "196  /title/tt2119532/ratings/?ref_=tt_ov_rt           NaN                NaN   \n",
       "209                                     None      471368.0                NaN   \n",
       "242                                     None      102143.0                NaN   \n",
       "\n",
       "     critic_review_count  budget  revenue_usa  revenue_usa_opening  \\\n",
       "56                   NaN     NaN          NaN                  NaN   \n",
       "147                  NaN     NaN          NaN                  NaN   \n",
       "164                  NaN     NaN          NaN                  NaN   \n",
       "196                  NaN     NaN          NaN                  NaN   \n",
       "209                  NaN     NaN          NaN                  NaN   \n",
       "242                  NaN     NaN          NaN                  NaN   \n",
       "\n",
       "     revenue_world  runtime opening_date release_date  \n",
       "56             NaN      NaN          NaT          NaT  \n",
       "147            NaN      NaN          NaT          NaT  \n",
       "164            NaN      NaN          NaT          NaT  \n",
       "196            NaN      NaN          NaT          NaT  \n",
       "209            NaN      NaN          NaT          NaT  \n",
       "242            NaN      NaN          NaT          NaT  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['release_date'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_df.to_csv('./cache/writers.csv', index=True)\n",
    "directors_df.to_csv('./cache/directors.csv', index=True)\n",
    "actors_df.to_csv('./cache/actors.csv', index=True)\n",
    "actor_movie_df.to_csv('./cache/actor_movie.csv', index=False)\n",
    "director_movie_df.to_csv('./cache/director_movie.csv', index=False)\n",
    "writers_movie_df.to_csv('./cache/writers_movie.csv', index=False)\n",
    "genres_movie_df.to_csv('./cache/genres_movie.csv', index=False)\n",
    "country_movie_df.to_csv('./cache/country_movie.csv', index=False)\n",
    "language_movie_df.to_csv('./cache/language_movie.csv', index=False)\n",
    "df.to_csv('./cache/movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"123,1231321\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '123,1231321'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/truonghoang/personal/dtl/notebooks/crawler.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/truonghoang/personal/dtl/notebooks/crawler.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfloat\u001b[39;49m(x)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '123,1231321'"
     ]
    }
   ],
   "source": [
    "float(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2430ba25cf41d6eca4db85f591fd1dcec92f913e1c3e8cd6a7a8dcc146299626"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dtl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
